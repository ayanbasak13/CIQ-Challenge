{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from tqdm import tqdm\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "lc = LancasterStemmer()\n",
    "from nltk.stem import SnowballStemmer\n",
    "sb = SnowballStemmer(\"english\")\n",
    "import gc\n",
    "from nltk.stem import WordNetLemmatizer   \n",
    "lemmatizer = WordNetLemmatizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\envs\\tfenv\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "spell_model = gensim.models.KeyedVectors.load_word2vec_format('wiki-news-300d-1M/wiki-news-300d-1M.vec')\n",
    "words = spell_model.index2word\n",
    "w_rank = {}\n",
    "\n",
    "for i,word in enumerate(words):\n",
    "    w_rank[word] = i\n",
    "    \n",
    "WORDS = w_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use fast text as vocabulary\n",
    "def words(text): \n",
    "    return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "def P(word): \n",
    "    \"Probability of `word`.\"\n",
    "    # use inverse of rank as proxy\n",
    "    # returns 0 if the word isn't in the dictionary\n",
    "    return - WORDS.get(word, 0)\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    \"correction('quikly') returns quickly    correction('israil') returns israel\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "\n",
    "def singlify(word):\n",
    "    return \"\".join([letter for i,letter in enumerate(word) if i == 0 or letter != word[i-1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "obscene_words = ['sex','fuck','shit','cunt','gay','lesbian','ass','pussy','dick','penis','vagina','asshole','fap','porn',\\\n",
    "                 'masturbate','sperm','semen','pregnate','impregnate','boobs','getting laid','get laid','bitch','undress','castrate',\\\n",
    "                 'castration','incest','sexual','rape','hooker','slut','prostitute','panty','bikini','underwear',\\\n",
    "                'dildo','breast','transgender','homosexual','anal','butt','bra','paedophilo','']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chk_words(s) :\n",
    "    flag = 0\n",
    "    \n",
    "    s=s.split()\n",
    "    for w in s :\n",
    "        #print(w + \"##\")\n",
    "        if(flag == 1) :\n",
    "            #print(flag)\n",
    "            break\n",
    "            \n",
    "        if(w in obscene_words) :\n",
    "            flag = 1\n",
    "            continue\n",
    "            \n",
    "        word = w.lower()\n",
    "        if(word in obscene_words) :\n",
    "            flag = 1\n",
    "            continue\n",
    "            \n",
    "        word = w.upper() \n",
    "        if(word in obscene_words) :\n",
    "            flag = 1\n",
    "            continue\n",
    "            \n",
    "        word = w.capitalize() \n",
    "        if(word in obscene_words) :\n",
    "            flag = 1\n",
    "            continue\n",
    "            \n",
    "        word = ps.stem(w)\n",
    "        if(word in obscene_words) :\n",
    "            flag = 1\n",
    "            continue\n",
    "            \n",
    "        word = lc.stem(w)\n",
    "        if(word in obscene_words) :\n",
    "            flag = 1\n",
    "            continue\n",
    "            \n",
    "        word = sb.stem(w)\n",
    "        if(word in obscene_words) :\n",
    "            flag = 1\n",
    "            continue\n",
    "            \n",
    "        if(len(w) > 1) :\n",
    "            word = correction(w)\n",
    "            if(word in obscene_words) :\n",
    "                flag = 1\n",
    "                continue\n",
    "    \n",
    "        word = lemmatizer.lemmatize(w)\n",
    "        if(word in obscene_words) :\n",
    "            flag = 1\n",
    "            continue\n",
    "                \n",
    "\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "sent = \"Can Aman pregnate a cow?\"\n",
    "\n",
    "print(chk_words(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
